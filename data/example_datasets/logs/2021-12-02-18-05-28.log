2021-12-02 18:05:28
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY++++++++++++++++++++++++++++++++++++++++
 Status:
     mode                 : train
 ++++++++++++++++++++++++++++++++++++++++
 Datasets:
     datasets         fold: data/example_datasets
     train            file: train.csv
     validation       file: dev.csv
     vocab             dir: data/example_datasets/vocabs
     delimiter            : b
     use              bert: False
     use            bilstm: True
     finetune             : False
     checkpoints       dir: checkpoints/bilstm-crf
     log               dir: data/example_datasets/logs
 ++++++++++++++++++++++++++++++++++++++++
Labeling Scheme:
     label          scheme: BIO
     label           level: 2
     suffixes             : ['ORG', 'PER', 'LOC']
     measuring     metrics: ['precision', 'recall', 'f1', 'accuracy']
 ++++++++++++++++++++++++++++++++++++++++
Model Configuration:
     embedding         dim: 300
     max  sequence  length: 300
     hidden            dim: 200
     CUDA  VISIBLE  DEVICE: 0
     seed                 : 42
 ++++++++++++++++++++++++++++++++++++++++
 Training Settings:
     epoch                : 3
     batch            size: 32
     dropout              : 0.5
     learning         rate: 0.0005
     optimizer            : Adam
     checkpoint       name: model
     max       checkpoints: 3
     print       per_batch: 10
     is     early     stop: True
     patient              : 5
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY END++++++++++++++++++++++++++++++++++++++++
loading vocab...
dataManager initialed...
mode: train
loading data...
loading data...
training set size: 4168, validating set size: 937
++++++++++++++++++++training starting++++++++++++++++++++
epoch:1/3
training batch:    10, loss: 77.45998, precision: 0.000 recall: 0.000 f1: -1.000 accuracy: 0.766 
training batch:    20, loss: 26.72603, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.899 
training batch:    30, loss: 24.39778, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.912 
training batch:    40, loss: 30.45771, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.859 
training batch:    50, loss: 35.91499, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.833 
training batch:    60, loss: 23.60193, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.880 
training batch:    70, loss: 34.24522, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.842 
training batch:    80, loss: 24.67849, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.871 
training batch:    90, loss: 16.08688, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.918 
training batch:   100, loss: 26.87352, precision: 0.000 recall: 0.000 f1: -1.000 accuracy: 0.837 
training batch:   110, loss: 27.29321, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.845 
training batch:   120, loss: 13.43510, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.903 
training batch:   130, loss: 13.13839, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.863 
start evaluate engines...
label: ORG, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.000 
label: PER, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.000 
label: LOC, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.000 
time consumption:2.98(min), precision: -0.933 recall: 0.000 f1: -1.000 accuracy: 0.902 
epoch:2/3
training batch:    10, loss: 16.05132, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.905 
training batch:    20, loss: 18.20663, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.895 
training batch:    30, loss: 28.49449, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.817 
training batch:    40, loss: 16.43139, precision: 0.000 recall: 0.000 f1: -1.000 accuracy: 0.920 
training batch:    50, loss: 12.18886, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.923 
training batch:    60, loss: 13.39830, precision: 0.667 recall: 0.043 f1: 0.080 accuracy: 0.910 
training batch:    70, loss: 15.64182, precision: 0.444 recall: 0.077 f1: 0.131 accuracy: 0.875 
training batch:    80, loss: 15.86962, precision: 0.444 recall: 0.075 f1: 0.129 accuracy: 0.881 
training batch:    90, loss: 13.51631, precision: 0.167 recall: 0.022 f1: 0.039 accuracy: 0.914 
training batch:   100, loss: 12.14994, precision: 0.222 recall: 0.091 f1: 0.129 accuracy: 0.913 
training batch:   110, loss: 11.77617, precision: 0.571 recall: 0.089 f1: 0.154 accuracy: 0.909 
training batch:   120, loss: 10.50160, precision: 0.400 recall: 0.100 f1: 0.160 accuracy: 0.922 
training batch:   130, loss: 8.99525, precision: 0.333 recall: 0.143 f1: 0.200 accuracy: 0.959 
start evaluate engines...
label: ORG, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.000 
label: PER, precision: 0.000 recall: 0.000 f1: 0.000 accuracy: 0.000 
label: LOC, precision: 0.260 recall: 0.186 f1: 0.201 accuracy: 0.000 
time consumption:3.19(min), precision: 0.381 recall: 0.140 f1: 0.197 accuracy: 0.918 
saved the new best model with f1: 0.197
epoch:3/3
training batch:    10, loss: 14.00866, precision: 0.200 recall: 0.073 f1: 0.107 accuracy: 0.882 
training batch:    20, loss: 12.83926, precision: 0.400 recall: 0.122 f1: 0.188 accuracy: 0.898 
training batch:    30, loss: 9.89611, precision: 0.435 recall: 0.250 f1: 0.317 accuracy: 0.930 
training batch:    40, loss: 11.38291, precision: 0.400 recall: 0.133 f1: 0.200 accuracy: 0.924 
training batch:    50, loss: 10.59496, precision: 0.391 recall: 0.209 f1: 0.273 accuracy: 0.937 
training batch:    60, loss: 14.06402, precision: 0.425 recall: 0.250 f1: 0.315 accuracy: 0.906 
training batch:    70, loss: 8.16760, precision: 0.438 recall: 0.250 f1: 0.318 accuracy: 0.938 
training batch:    80, loss: 10.53564, precision: 0.350 recall: 0.167 f1: 0.226 accuracy: 0.923 
training batch:    90, loss: 11.28617, precision: 0.407 recall: 0.208 f1: 0.275 accuracy: 0.915 
training batch:   100, loss: 11.54662, precision: 0.263 recall: 0.185 f1: 0.217 accuracy: 0.921 
training batch:   110, loss: 9.45718, precision: 0.419 recall: 0.325 f1: 0.366 accuracy: 0.932 
training batch:   120, loss: 14.35287, precision: 0.294 recall: 0.213 f1: 0.247 accuracy: 0.908 
training batch:   130, loss: 14.52583, precision: 0.286 recall: 0.200 f1: 0.235 accuracy: 0.942 
start evaluate engines...
label: ORG, precision: 0.257 recall: 0.118 f1: 0.157 accuracy: 0.000 
label: PER, precision: 0.272 recall: 0.048 f1: 0.081 accuracy: 0.000 
label: LOC, precision: 0.297 recall: 0.348 f1: 0.311 accuracy: 0.000 
time consumption:3.61(min), precision: 0.428 recall: 0.298 f1: 0.346 accuracy: 0.933 
saved the new best model with f1: 0.346
overall best f1 is 0.34550585658755606 at 3 epoch
total training time consumption: 9.814(min)
